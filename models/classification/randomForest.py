# # ğŸŒ³ Random Forest Classifier
# #
# import numpy as np
# import pandas as pd
# import matplotlib.pyplot as plt
# import seaborn as sns
# from sklearn import preprocessing, metrics
# from sklearn.model_selection import train_test_split
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.tree import plot_tree
# import warnings
# warnings.filterwarnings("ignore")
#
# # ---------------- 1. è¯»å–æ•°æ® ----------------
# file_name = "D:/MyProject/MatContest/dataset/raw/yf2014_2018.csv"
# dataset = pd.read_csv(file_name)
#
# # ---------------- 2. æ„é€ æ ‡ç­¾åˆ— ----------------
# dataset['Return'] = dataset['Close'].pct_change()
# dataset['Up_Down'] = np.where(dataset['Return'].shift(-1) > dataset['Return'], 'Up', 'Down')
#
# # ---------------- 3. æ„é€ ç‰¹å¾åˆ— ----------------
# dataset['Open_N']   = np.where(dataset['Open'].shift(-1)   > dataset['Open'],   'Up', 'Down')
# dataset['Volume_N'] = np.where(dataset['Volume'].shift(-1) > dataset['Volume'], 'Positive', 'Negative')
#
# # å»æ‰ç¼ºå¤±å€¼ï¼ˆå› ä¸ºæœ‰ shift æ“ä½œï¼‰
# dataset = dataset.dropna()
#
# # ---------------- 4. åˆ’åˆ†ç‰¹å¾Xã€ç›®æ ‡y ----------------
# X = dataset[['Open', 'Open_N', 'Volume_N']].values
# y = dataset['Up_Down']
#
# # ---------------- 5. æ ‡ç­¾ç¼–ç  ----------------
# le_Open = preprocessing.LabelEncoder()
# le_Open.fit(['Up','Down'])
# X[:,1] = le_Open.transform(X[:,1])
#
# le_Volume = preprocessing.LabelEncoder()
# le_Volume.fit(['Positive','Negative'])
# X[:,2] = le_Volume.transform(X[:,2])
#
# # ---------------- 6. åˆ’åˆ†è®­ç»ƒé›†ä¸æµ‹è¯•é›† ----------------
# X_train, X_test, y_train, y_test = train_test_split(
#     X, y, test_size=0.2, random_state=0
# )
#
# # ---------------- 7. è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹ ----------------
# rf = RandomForestClassifier(
#     n_estimators=100,
#     max_depth=None,
#     random_state=0
# )
# rf.fit(X_train, y_train)
#
# # ---------------- 8. é¢„æµ‹ä¸è¯„ä¼° ----------------
# y_pred = rf.predict(X_test)
# acc = metrics.accuracy_score(y_test, y_pred)
# print("Random Forest Accuracy:", acc)
#
# # ---------------- 9. å¯è§†åŒ–ï¼šæ··æ·†çŸ©é˜µ ----------------
# cm = metrics.confusion_matrix(y_test, y_pred, labels=rf.classes_)
#
# plt.figure(figsize=(5,4))
# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
#             xticklabels=rf.classes_, yticklabels=rf.classes_)
# plt.xlabel('Predicted')
# plt.ylabel('True')
# plt.title('Confusion Matrix')
# plt.show()
#
# # ---------------- 10. å¯è§†åŒ–ï¼šç‰¹å¾é‡è¦æ€§ ----------------
# feature_names = ['Open', 'Open_N', 'Volume_N']
# importances = rf.feature_importances_
#
# plt.figure(figsize=(5,4))
# sns.barplot(x=importances, y=feature_names)
# plt.title('Feature Importances')
# plt.show()
#
# # ---------------- 11. å¯è§†åŒ–ï¼šå•æ£µæ ‘ç»“æ„ï¼ˆå¯é€‰ï¼‰ ----------------
# plt.figure(figsize=(15, 10))
# plot_tree(rf.estimators_[0], feature_names=feature_names,
#           class_names=rf.classes_, filled=True, max_depth=4)
# plt.title('Example Tree from Random Forest')
# plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import preprocessing, metrics
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import plot_tree
import warnings
warnings.filterwarnings("ignore")

# ---------------- 1. è¯»å–æ•°æ® ----------------
file_name = "D:/MyProject/MatContest/dataset/raw/yf2014_2018.csv"
dataset = pd.read_csv(file_name)

# ---- åŸºç¡€ä»·å·®ç±»ç‰¹å¾ ----
dataset['High_Low_Spread'] = dataset['High'] - dataset['Low']                # å½“æ—¥æœ€é«˜-æœ€ä½
dataset['Close_Open_Change'] = dataset['Close'] - dataset['Open']            # æ”¶ç›˜-å¼€ç›˜
dataset['Return'] = dataset['Close'].pct_change()                             # æ—¥æ”¶ç›Šç‡
dataset['Volume_Change'] = dataset['Volume'].pct_change()                     # æˆäº¤é‡å˜åŒ–ç‡

# ---- ç§»åŠ¨å¹³å‡å’ŒåŠ¨é‡ç±»ç‰¹å¾ ----
dataset['MA_5'] = dataset['Close'].rolling(window=5).mean()
dataset['MA_10'] = dataset['Close'].rolling(window=10).mean()
dataset['MA_20'] = dataset['Close'].rolling(window=20).mean()

dataset['Momentum_5'] = dataset['Close'] - dataset['Close'].shift(5)
dataset['Momentum_10'] = dataset['Close'] - dataset['Close'].shift(10)

# ---- æ³¢åŠ¨æ€§ç‰¹å¾ ----
dataset['Rolling_STD_5'] = dataset['Close'].rolling(window=5).std()
dataset['Rolling_STD_10'] = dataset['Close'].rolling(window=10).std()

# ---- ç§»åŠ¨å¹³å‡æ”¶æ•›å·®æŒ‡æ ‡ï¼ˆMACDï¼‰ ----
ema12 = dataset['Close'].ewm(span=12, adjust=False).mean()
ema26 = dataset['Close'].ewm(span=26, adjust=False).mean()
dataset['MACD'] = ema12 - ema26

# ---- ç›¸å¯¹å¼ºå¼±æŒ‡æ•°ï¼ˆRSIï¼‰ ----
delta = dataset['Close'].diff()
gain = np.where(delta > 0, delta, 0)
loss = np.where(delta < 0, -delta, 0)
avg_gain = pd.Series(gain).rolling(window=14).mean()
avg_loss = pd.Series(loss).rolling(window=14).mean()
rs = avg_gain / avg_loss
dataset['RSI_14'] = 100 - (100 / (1 + rs))

dataset['Up_Down'] = np.where(dataset['Return'].shift(-1) > dataset['Return'], 'Up', 'Down')

dataset.replace([np.inf, -np.inf], np.nan, inplace=True)
dataset.dropna(inplace=True)
dataset.reset_index(drop=True, inplace=True)

features = [
    'Open','High','Low','Close','Volume',
    'High_Low_Spread','Close_Open_Change','Return','Volume_Change',
    'MA_5','MA_10','MA_20','Momentum_5','Momentum_10',
    'Rolling_STD_5','Rolling_STD_10','MACD','RSI_14'
]
X = dataset[features].values
y = dataset['Up_Down']

# ---------------- 6. åˆ’åˆ†è®­ç»ƒé›†ä¸æµ‹è¯•é›† ----------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=0
)
# ---------------- 7. è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹ ----------------
rf = RandomForestClassifier(
    n_estimators=100,
    max_depth=None,
    random_state=0
)
rf.fit(X_train, y_train)
# ---------------- 8. é¢„æµ‹ä¸è¯„ä¼° ----------------
y_pred = rf.predict(X_test)
acc = metrics.accuracy_score(y_test, y_pred)
print("Random Forest Accuracy:", acc)

# ---------------- 9. å¯è§†åŒ–ï¼šæ··æ·†çŸ©é˜µ ----------------
cm = metrics.confusion_matrix(y_test, y_pred, labels=rf.classes_)

plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=rf.classes_, yticklabels=rf.classes_)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# ---------------- 10. å¯è§†åŒ–ï¼šç‰¹å¾é‡è¦æ€§ ----------------
feature_names = features
importances = rf.feature_importances_

plt.figure(figsize=(5,4))
sns.barplot(x=importances, y=feature_names)
plt.title('Feature Importances')
plt.show()

# ---------------- 11. å¯è§†åŒ–ï¼šå•æ£µæ ‘ç»“æ„ï¼ˆå¯é€‰ï¼‰ ----------------
plt.figure(figsize=(15, 10))
plot_tree(rf.estimators_[0], feature_names=feature_names,
          class_names=rf.classes_, filled=True, max_depth=4)
plt.title('Example Tree from Random Forest')
plt.show()



